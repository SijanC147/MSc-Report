% !TEX root = ../../fyp.tex
\documentclass[../../fyp.tex]{subfiles}

\begin{document}

We draw a number of conclusions from the development of this framework and its evolution, however, one over-arching observation stands out, and affects all others. 

\section{Conclusions}
The degree of difficulty and complexity that arises from decomposing a machine learning pipeline, even when limited to a individual task, cannot be understated. Although a subset of these challenges stem from having to deal with particular irregularities or inconsistencies within datasets or embeddings, this is not the source of these issues. The primary source of these obstacles lies in the overly-ambitious approach we adopted in development by attempting to account for all edge-cases: focus was placed on the having the widest of the coverage of such cases at the cost of depth in other areas. 

As a result, our framework succesfully meets the objectives we set out to accomplish \textit{functionally}, in that it provides a simple and accessible means of rapidly evaluating TSA models, with access to a wealth of different datasets and embeddings. We also provide an expansive means of interacting with the framework on a deeper level, through specific entry points which allow users to build on top of the framework and extend its functionality with minimal effort. The majority of the time was spent in developing these features, some of which would not be used in the experiments that followed, others still which we were unable to complete, such as GPU integration and the ability to export a trained model for predictions.

In spite of this, we draw the following conclusions with respect to the original objectives (as defined in \S\ref{sec:objectives}):

\begin{enumerate}
	\item While focusing primarily on the development of the framework placed time-constraints on our experimentation objectives, as we documented, this was further intensified during our reproduction experiments by missing parameters and implementation details. The extent to which this is a factor, both in time and cost, cannot be understated. From our work in reproducibility we identify this as one of three issues poised to hold back further development of the field. We conclude that more emphasis must be made on the importance of making all code publically accessible when developing new techniques and approaches. The second is the importance of reporting performance in terms of multiple runs when using random initialization, and finally the significance of appropriate performance metric when dealing with unbalanced datasets. 
	\item When considering the OOV clustering technique adopted in our latter experiments, we conclude that this approach requires much deeper investigation for it to be substantiated. We show from our experiments that the configuration alterations we propose do have noticeable downstream effects, however we note that this approach itself consists of a number of tunable parameters, and the extent to which the effectiveness of the approach is contingent on these parameters is still unknown. The OOV clustering approach may show more pronounced effects when dealing with larger amounts of OOV tokens. We could not carry out these experiments due to time and monetary cost, however the framework provides a means of exploring this issue further through it's dataset merging and re-distributing features. Moreover, we also identify the clustering function itself as another point of future development in this approach. 
\end{enumerate}

\section{Future Work}
In addition to the aforementioned research topics to pursue further, the framework itself needs to grow and evolve accordingly. Particularly when exploring clustering techniques, the framework must adapt and provide a simple entry point for the end-user to alter this clustering function, while adhering to the same modular principles of the framework. On the same note, ease of use of the framework can be greatly improved through the inclusion of a graphical interface. We also note that that scope of this work has been confined to a 3-point scale of sentiment, one of the few hard-coded limitations of the framework, venturing beyond this limit would also increase the applicability of the framework for future research. 

\section{Final Remarks}
Shortcomings notwithstanding, the principles adopted in the design and implementation of the framework, specifically the modular architecture, were invaluable at later stages of the work when we were required to run large amounts of experiments with, at times minuscule, alterations. The framework greatly simplified the process, requiring only command line parameter changes for most, abstracting the more complex and error-prone tasks from the user. While achieving this level of abstraction and ease of use were the most arduous components of the work as a whole, it demanded a deep understanding of all the moving parts within a TSA-oriented machine learning pipeline, the achievement of which has proved to be a rewarding aspect of this dissertation. It now remains to see whether lessons learned will be of benefit to the field as a whole in the not too distant future.

% \section{Conclusions}
% \subfile{chapters/7-Conclusion/7.1-Conclusions.tex}

% \section{Future Work}
% \subfile{chapters/7-Conclusion/7.2-FutureWork.tex}

\end{document}

