% !TEX root = ../../fyp.tex
\documentclass[../../fyp.tex]{subfiles}

\begin{document}
\subsection{Model Graph}
The model graph provides an intuitive way of visualizing the architecture and data flow of a model. Nodes are used to represent single operations or groups thereof, and connections represent the tensor data that flows from one operation to the next.\footnote{https://www.tensorflow.org/guide/graph\_viz} 

\subsection{Histograms}
Histograms illustrate the evolution of tensor distributions with training. Internally, the framework attempts to produce histograms for all tensors identified as subject to training.\footnote{https://www.tensorflow.org/guide/tensorboard\_histograms}

\subsection{Embedding Projections}
When preparing feature data for an experiment, the framework also generates a tab-separated-value (tsv) file which lists all the tokens, including any OOV buckets, in the order they appear in the embedding. This file can be used in conjunction with the Tensorboard projector tool to attach labels to points in  the embedding matrix projected in $\mathbb{R}^3$ space using principal component analysis (PCA). This is useful when embedding vectors are trained alongside the model and may provide additional insights into how the representation of OOV buckets evolves with respect to other tokens by visualizing neighboring points.
%TODO Include an example image of embedding visualized in this way, possibly showing nearest neighbors of OOV buckets

\subsection{Dataset Distribution Figure}
Two pie-charts are generated for the training and test datasets which depict the class distribution of the each dataset. Moreover, in the case where merged datasets are used, the contribution of each constituent dataset and their respective class distributions are also included in this figure. 

This type of visualization intuitively highlights class imbalances as well as their sources while also efficiently conveying the contribution of each dataset relative to the others in a merged dataset.
%TODO Include image of a dataset distribution piechart

\subsection{Confusion Matrix}
Matplotlib\footnote{https://matplotlib.org/} was used to render most of the visualizations offered by the framework as it offers an extensive tool-set. The confusion matrix is generated using a custom-built hook and provides a broad overview of the performance of the model. It is rendered as a heat-map spread across all samples of the evaluation dataset. Although this information may be condensed into equally informative scalar metrics, such as the macro-F1, the confusion matrix may convey more insight into the per-class transient performance of the model. Ideally, with training, the heat-map should consolidate across the diagonal of the matrix.
%TODO Include example image of multiple confusion matrices over time showing how the heatmap distribution changes over time

\subsection{Attention Heat-maps}
Attention weight vectors are obtained using custom implementations of attention units which expose these data and their corresponding string tokens. These are used by the add-on to produce attention heat-maps for a select subset of samples from each batch during evaluation checkpoints. The size of this subset can be adjusted using the auxiliary configuration parameters to avoid excessive heat-maps from being generated for increasingly large datasets. 

The attention heat-maps use a color-map to contrast the different weights being placed on each token. Over time, as the model learns to distinguish which tokens maximally contribute to the sentiment of a sentence, these tokens are expected to be highlighted relative to their surroundings which signifies a stronger attention weight. Two attention heat-maps are generated for each sample, the first illustrating the color-coded attention weight distribution corresponding to each string token whereas the second supplementing the first with the precise real-valued weights.

For models that employ multiple hops, such as memory networks, the process is repeated for each hop. These models are expected to concentrate their attention on the most salient tokens with each hop, as well as improving this process on the whole ov er multiple evaluation checkpoints.
%TODO Include two images of attention maps one for the normal case showing both generated types and one for memory networks showing multiple hops
\end{document}