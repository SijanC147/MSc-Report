% !TEX root = ../../fyp.tex
\documentclass[../../fyp.tex]{subfiles}

% The problem from mooore:
% models make it difficult to recreate results, 
% everyone tests on different data 
% not everyone uses the same metrics
% there is a lack of consistency.

% Problem from dhingra
% OOV are unavoidable, and single tokens might lack resolution
% intelligently bucketing might provide benefits 
% could address OOV problem with minimal resource overhead

\begin{document}
% Moore et al. \cite{moore2018} shed light on the problem of reproducibility in the field and detail the detrimental effects of this on TSA as a whole. Development of novel architechtures that push the state-of-the-art (SOTA) are possible only after determining the current SOTA, and reproducibility is fundamental for doing so. For this reason we agree with the authors' evaluation of the severity of this problem and its repurcussions, which motivates us to re-visit the issue and evaluate the present state of reproducibility covering a wider range of studies and techniques that followed their work. To tackle this task, we develop a framework with the intent of addressing the problems specified by \cite{moore2018} in the field of TSA, namely,

% \begin{enumerate}
% 	\item Underspecification of the methodology used.
% 	\item No accompanying code-base to facilitate reproducing the reported results.
% 	\item No access to the datasets as used for a study, including any processing and stratification strategies employed.
% \end{enumerate}

% Our framework tackles these issues by streamlining TSA model development, making it easier for authors to account for them. Moreover, we identify and address an additional problem which results from these issues: The inability to compare and contrast different TSA models in an impartial environment, where all components of the machine learning pipeline, save for the model itself, are maintained constant.

Motivated by the observations made by Dhingra et al. \cite{bhuwandhingra2017} in the field of reading comprehension and the effect of out-of-vocabulary (OOV) embedding strategies thereof, and as an application of our framework, we approach the problem of OOV words in TSA. Specifically, is it possible to mitigate the detrimental effects of OOV words by applying marginally more sophisticated bucketing strategies with minimal computational overhead?

The objectives of this study, therefore, are two-fold.

\begin{enumerate}
	\item We propose to extend the work carried out by Moore et al. \cite{moore2018} in the field of TSA to cover a wider range of studies, including those that employ techniques that have since emerged focusing on attention mechanisms and memory networks. This entails the attempt to reproduce these models based on the detail provided in the original studies and subsequently carrying out a comparative evaluation of these approaches across a wide range of datasets from varying domains using a number of different pre-trained word embeddings.
	\item Inspired by the work and findings of Dhingra et al. \cite{bhuwandhingra2017}, we shall endeavor to investigate the effect that different OOV embedding strategies and pre-trained word embeddings have on the downstream performance of models with respect to TSA. To our knowledgehttps://www.overleaf.com/project/5b646d81fa631449659b0dc0, at the time of writing, this study will be the first to investigate this issue in detail.
\end{enumerate}

To achieve these objectives, we make three principal contributions through this work:
\begin{itemize}
	\item A publicly accessible framework that provides access to a range of frequently cited datasets that have been used in the field of TSA. This framework shall be used to obtain robust performance metrics, such as macro-f1 scores for all models, which have been hitherto unreported for a subset of the models, as well as other informative measures that shed light into the inner workings of the models implemented, such as attention heat-maps (where applicable).
	\item A comparative evaluation of models across different domains and datasets, using different pre-trained word embeddings to ascertain the degree to which results obtained are reproducible and generalizable.
	\item Detailed reports on a series of experiments using different OOV embedding strategies across all implemented models, the results of which will allow us to deduce the degree to which these affect downstream performance and whether an optimal approach can be found that proves to be generally beneficial.
\end{itemize}

Finally, the proposed framework shall also serve as the groundwork for future experimentation into alternative, more sophisticated, OOV embedding approaches while also providing a means of rapidly carrying out comparative evaluations of TSA models across different datasets and pre-trained word embeddings.


\end{document}